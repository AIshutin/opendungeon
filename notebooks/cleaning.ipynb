{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "752b6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import seaborn as sns\n",
    "import os\n",
    "import transformers\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\", cache_dir=\"mycache\")\n",
    "MAX_INPUT_TOKENS = 2048\n",
    "MAX_INPUT_WORDS = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b40cc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019723892211914062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 870,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98d154cbc954bbba805a4d1f3b2e765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2104 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m curr_actions \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery_texts\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m text \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m descriptions\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     14\u001b[0m descriptions_texts\u001b[38;5;241m.\u001b[39mappend((text, \u001b[38;5;28mlen\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mencode(text)), el))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m curr_actions:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2176\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2138\u001b[0m \u001b[38;5;129m@add_end_docstrings\u001b[39m(\n\u001b[1;32m   2139\u001b[0m     ENCODE_KWARGS_DOCSTRING,\n\u001b[1;32m   2140\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2159\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   2160\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m   2161\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2162\u001b[0m \u001b[38;5;124;03m    Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.\u001b[39;00m\n\u001b[1;32m   2163\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2174\u001b[0m \u001b[38;5;124;03m            ``convert_tokens_to_ids`` method).\u001b[39;00m\n\u001b[1;32m   2175\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2176\u001b[0m     encoded_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2179\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2185\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2186\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m encoded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2503\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2494\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2495\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   2496\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2500\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2501\u001b[0m )\n\u001b[0;32m-> 2503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2506\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2521\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py:173\u001b[0m, in \u001b[0;36mGPT2TokenizerFast._encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m )\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py:479\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    458\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    476\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[1;32m    478\u001b[0m     batched_input \u001b[38;5;241m=\u001b[39m [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[0;32m--> 479\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py:163\u001b[0m, in \u001b[0;36mGPT2TokenizerFast._batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m )\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py:406\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_truncation_and_padding(\n\u001b[1;32m    399\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[1;32m    400\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m    404\u001b[0m )\n\u001b[0;32m--> 406\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    418\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[1;32m    420\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[1;32m    430\u001b[0m ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "files = [os.path.join('data', el) for el in os.listdir('data')]\n",
    "\n",
    "descriptions = []\n",
    "actions = []\n",
    "actions_texts = []\n",
    "descriptions_texts = []\n",
    "\n",
    "for el in tqdm(files):\n",
    "    j = json.load(open(el))\n",
    "    for key, state in j.items():\n",
    "        curr_actions = state['query_texts']\n",
    "        text = state['main_text']\n",
    "        descriptions.append(len(tokenizer.encode(text)))\n",
    "        descriptions_texts.append((text, len(tokenizer.encode(text)), el))\n",
    "        for action in curr_actions:\n",
    "            actions.append(len(tokenizer.encode(action)))\n",
    "            actions_texts.append((action, len(tokenizer.encode(action)), el))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4989c48",
   "metadata": {},
   "source": [
    "### Tricky actions:\n",
    "- I will cast a minor spell which allows the air to carry the sound to my ear. [You can do that even without being specialized in Air.]\n",
    "- \"Let’s arrange a marriage of our children. How about one of your kids gets to marry one of mine?\" (unofficial, informal, and politically inconsequential understanding usually ignored outside of the enjoined kingdoms)\n",
    "- \"Let’s swear to a military alliance between us two.\" (peace agreement + provide troops and other military aid to the other as needed, an internationally recognized edict which tends to increase war and violent conflict)\n",
    "- Fire your ballistae at and destroy Minâ€™s own ballistae installations; once his ballistae are eliminated, advance your cloud ladders, carrying a mix of infantry and archers, to storm the walls and capture the keep\n",
    "- NOOOOOOOOO! I DIED! CURSE YOU SENTINELPENGUIN!!!\n",
    "- Needles wonâ€™t puncture his skin, so he squirts it out his eye ducts\n",
    "- The Epirus-Rome War (280-279BC) - MEDIUM DIFFICULTY\n",
    "- 2: The Athens-Sparta War (432-418BC) - HARD DIFFICULTY\n",
    "- Don’t care, you need to drink – get some of the water from under the pier\n",
    "- “It’s OK, I’m just passing through,” you reply truthfully\n",
    "- 4th British defenders\n",
    "- Evidence: Attorneys Badge\n",
    "- , Ko e fasi 'o e tu'i 'o e 'Otu Tonga\n",
    "- Dossier: Double Trouble\n",
    "- List of Noted Sailors of the Three Kingdoms\n",
    "- MAIN MENU\n",
    "- Synopsis mode. (Was there something you wanted to know? Click here!) *Spoiler Alert!*\n",
    "- HARD: You are an eighteen year old, up-and-coming female model in India. A company called Pond's has asked you if you'd like to do a commerical with them. You are at their office, waiting to discuss the potential contract. data/are-you-happy-with-your-choices~3f.json\n",
    "- (Intelligence) Rhode is a hypocrite. She might brag about her years in the arena, but she’s never surrendered to an honourable death. I point out as much, no matter what punishment it might get me. data/The-Price-of-Freedom~3a-Innocence-Lost.json\n",
    "- \"So, that's Pegasi Station - an impressive piece of technology,\" the captain said. \"Lieutenant Gregari, other than humans, which species inhabit this station?\" (Turn to Section - 54)\n",
    "-  Zorek isn’t interested in the bureaucracy. He will go and find someone in charge\n",
    "- If you think it's best to stay put and wait for Andrade's return, turn to page 115. data/Marooned-on-Giri-Minor.json\n",
    "- Accept the King of Merrywed's marriage proposal in exchange for protection: go to section 8a if you sent soldiers with the messengers data/Survive-or-Conquer.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "banned = [\"are-you-happy-with-your-choices~3f.json\", \"Warlords~3a-Strategic-Conquest.json\", \n",
    "          \"Survive-or-Conquer.json\", \"Maintenance-Systems.json\", \"Algebra-Game.json\",\n",
    "          \"Tower-of-Doom.json\", \"Practice-Simple-Italian.json\"]\n",
    "phrase_ban = [\"Synopsis\", \"MENU\", \"HARD\", \"EASY\", \"MEDIUM\", \"Turn to Section\", \"go to section\", \n",
    "              \"turn to page\", \"go to page\", \"\t\t\t\t\t\", \"Start over\", \"END THE GAME\", \"Rating:\",\n",
    "             \"Rank:\"]\n",
    "\n",
    "for text, l, src in actions_texts:\n",
    "    is_banned = False\n",
    "    for ban in banned:\n",
    "        if ban in src:\n",
    "            is_banned = True\n",
    "    for phrase in phrase_ban:\n",
    "        if phrase in text:\n",
    "            is_banned = True\n",
    "    if is_banned:\n",
    "        continue\n",
    "    if l < 20:\n",
    "        continue\n",
    "    print(l, len(text), text, src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d10a1",
   "metadata": {},
   "source": [
    "### Tricky descriptions:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e6b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "banned = [\"are-you-happy-with-your-choices~3f.json\", \"Warlords~3a-Strategic-Conquest.json\", \n",
    "          \"Survive-or-Conquer.json\", \"Maintenance-Systems.json\", \"Sixteen-Words.json\", \n",
    "          \"How-well-do-you-know-your-British~2dEnglish~3f.json\", \"Harry-Potter-and-the-Deathly-Hallows-Quiz.json\",\n",
    "         \"Monster-Trivia.json\", \"Z~2dDAY-Survival-Quiz.json\", \"Battlefield-Commander~3a-Ancient-Warfare.json\", \n",
    "         \"Algebra-Game.json\", \"Tower-of-Doom.json\", \"Practice-Simple-Italian.json\", \"ENG4U1-Seminar-Game.json\",\n",
    "         \"Eating-Disorders-Midterm.json\"]\n",
    "# todo ban any quiz\n",
    "phrase_ban = [\"Synopsis\", \"MENU\", \"HARD\", \"EASY\", \"MEDIUM\", \"Turn to Section\", \"go to section\", \n",
    "              \"turn to page\", \"go to page\", \"\t\t\t\t\t\", \"Start over\", \"END THE GAME\", \"Rating:\",\n",
    "             \"Rank:\", \"THE END\", \"The end\", \"The End\", \"Please play again\", \"YOUR HEALTH\", \n",
    "              \"Your score was\", \"Your score is\"]\n",
    "from time import sleep\n",
    "\n",
    "for text, l, src in descriptions_texts:\n",
    "    if \"quiz\" in src.lower():\n",
    "        continue\n",
    "    is_banned = False\n",
    "    for ban in banned:\n",
    "        if ban in src:\n",
    "            is_banned = True\n",
    "    has_phrase = False\n",
    "    for phrase in phrase_ban:\n",
    "        if phrase in text:\n",
    "            has_phrase = True\n",
    "    if is_banned:\n",
    "        continue\n",
    "    if has_phrase:\n",
    "        continue\n",
    "    if l < 400:\n",
    "        continue\n",
    "    print(l, len(text), text, src)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "313a82df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013645172119140625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 870,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698cba24d8c245d0a06f9961fee2b632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Facts-About-the-Planet-and-the-Solar-System.json Nodes banned: 10/48 Actions banned: 12/77\n",
      "File: A-Hero-is-Born,-Episode-2.json Nodes banned: 16/59 Actions banned: 15/58\n",
      "File: CYBERMONKEY.json Nodes banned: 4/17 Actions banned: 3/16\n",
      "File: Warped.json Nodes banned: 62/230 Actions banned: 95/266\n",
      "File: Reanimation-2.json Nodes banned: 15/72 Actions banned: 14/220\n",
      "File: Would-You-Survive-Daniel-Wilson's-Robopocalypse~3f.json Nodes banned: 5/23 Actions banned: 3/26\n",
      "File: De-Milite-Inprudenti.json Nodes banned: 25/94 Actions banned: 21/137\n",
      "File: The-Price-of-Freedom~3a-Innocence-Lost.json Nodes banned: 103/490 Actions banned: 126/871\n",
      "File: Edithe-Zilonis.json Nodes banned: 16/73 Actions banned: 16/73\n",
      "File: The-Witcher~3a-The-First-Wish.json Nodes banned: 24/83 Actions banned: 39/155\n",
      "File: A-Hero-is-Born~2e~2e.json Nodes banned: 4/14 Actions banned: 3/14\n",
      "File: Archangel.json Nodes banned: 8/33 Actions banned: 10/47\n",
      "File: Failing-.json Nodes banned: 27/119 Actions banned: 25/135\n",
      "File: The-Wasteland-Chronicles~3a-The-Story-of-Aether-Frost.json Nodes banned: 10/35 Actions banned: 6/36\n",
      "File: Solstice.json Nodes banned: 24/83 Actions banned: 25/95\n",
      "File: Hunting-the-Alphabet-Killer.json Nodes banned: 28/131 Actions banned: 52/231\n",
      "File: The-Unravelling-of-Order.json Nodes banned: 25/92 Actions banned: 25/128\n",
      "File: Why-I-left-you.json Nodes banned: 3/11 Actions banned: 3/13\n",
      "File: Live-the-Life-of-a-Cat.json Nodes banned: 5/24 Actions banned: 4/25\n",
      "File: A-Super-Tale.json Nodes banned: 35/145 Actions banned: 29/202\n",
      "File: A-Zombie-Night.json Nodes banned: 4/20 Actions banned: 11/32\n",
      "File: In-The-Deep-Of-Night.json Nodes banned: 22/80 Actions banned: 20/78\n",
      "File: Rings-of-Stone.json Nodes banned: 23/106 Actions banned: 31/201\n",
      "File: American-Outlaws~3a-The-Wild-Bunch.json Nodes banned: 48/204 Actions banned: 43/272\n",
      "File: Basement-Rats.json Nodes banned: 14/50 Actions banned: 17/54\n",
      "File: The-Cursed-Night.json Nodes banned: 22/85 Actions banned: 26/113\n",
      "File: Epoch-Coda-.json Nodes banned: 9/40 Actions banned: 11/45\n",
      "File: Shostakovich.json Nodes banned: 3/14 Actions banned: 3/14\n",
      "File: The-Veil.json Nodes banned: 67/235 Actions banned: 48/472\n",
      "File: Life-In-The-Fast-Lane.json Nodes banned: 6/25 Actions banned: 6/25\n",
      "File: Temple-of-Spades.json Nodes banned: 14/59 Actions banned: 22/110\n",
      "File: Personal-Demons.json Nodes banned: 31/129 Actions banned: 32/141\n",
      "File: Isotope-239.json Nodes banned: 17/85 Actions banned: 25/121\n",
      "File: A-UFO-at-School.json Nodes banned: 4/16 Actions banned: 4/19\n",
      "File: One-Tiny-but-Mighty-Pilchangk-Adventure.json Nodes banned: 12/56 Actions banned: 20/103\n",
      "File: A-Hero's-Odyssey.json Nodes banned: 45/193 Actions banned: 32/249\n",
      "File: Shadows-and-Blood-(or-What-Is-It-Like-to-Be-a-Vampire-Bat).json Nodes banned: 6/28 Actions banned: 6/30\n",
      "File: Cryogenic-Failure.json Nodes banned: 15/75 Actions banned: 22/137\n",
      "File: house-among-the-thorns.json Nodes banned: 6/27 Actions banned: 4/39\n",
      "File: Harry-Potter~3a-The-Last-Riddle.json Nodes banned: 35/136 Actions banned: 38/229\n",
      "File: Landslide.json Nodes banned: 9/31 Actions banned: 7/36\n",
      "File: Where-in-the-World-Is-Carmen-Sandiego~3f.json Nodes banned: 66/277 Actions banned: 228/1030\n",
      "File: Day-of-the-Dead~2d~2dOne-Soul's-All-Souls-Procession.json Nodes banned: 3/15 Actions banned: 1/17\n",
      "File: Battlefield-Commander~3a-The-Trojan-War.json Nodes banned: 21/73 Actions banned: 14/65\n",
      "File: Fallout-~3a-Seattle-under-Siege.json Nodes banned: 5/21 Actions banned: 2/62\n",
      "File: The-Spanish-Armada.json Nodes banned: 16/59 Actions banned: 33/78\n",
      "File: A-Knight's-Pursuit.json Nodes banned: 8/30 Actions banned: 10/32\n",
      "File: Engineered-Desires.json Nodes banned: 4/20 Actions banned: 7/25\n",
      "File: Mercenary-Queen-(Part-3)~3a-The-Hemlock-Band.json Nodes banned: 20/83 Actions banned: 26/111\n",
      "File: Vapula.json Nodes banned: 16/66 Actions banned: 26/87\n",
      "File: Cannibal-Apocalypse.json Nodes banned: 3/15 Actions banned: 3/16\n",
      "File: Halfway-Decent.json Nodes banned: 7/31 Actions banned: 10/36\n",
      "File: Through-The-Dragon-Lair.json Nodes banned: 5/19 Actions banned: 4/21\n",
      "File: Airport-Nightmare.json Nodes banned: 19/81 Actions banned: 19/102\n",
      "File: A-Mutt's-Purpose.json Nodes banned: 5/25 Actions banned: 9/41\n",
      "File: Save-Your-Dragon-.json Nodes banned: 21/95 Actions banned: 17/100\n",
      "File: The-Search-For-The-Craxil.json Nodes banned: 39/144 Actions banned: 20/156\n",
      "File: The-Lost-Expedition-(2).json Nodes banned: 11/55 Actions banned: 14/80\n",
      "File: Tower-of-Riddles.json Nodes banned: 73/336 Actions banned: 189/634\n",
      "File: Surviving-Pre~2dSchool.json Nodes banned: 12/60 Actions banned: 16/91\n",
      "File: A-British-Shipwright-Immigrant's-Life-in-Canada-(1830).json Nodes banned: 6/24 Actions banned: 8/32\n",
      "0.7206896551724138 627 870\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "_RE_COMBINE_WHITESPACE = re.compile(r\"\\s+\")\n",
    "\n",
    "\n",
    "def fix_spaces(s):\n",
    "    return _RE_COMBINE_WHITESPACE.sub(\" \", s).strip()\n",
    "\n",
    "def normalize_text(s):\n",
    "    s = s.strip()\n",
    "    s = fix_spaces(s)\n",
    "    s = s.replace('”', '\"')\n",
    "    s = s.replace('“', '\"')\n",
    "    s = s.replace('‘', \"'\")\n",
    "    s = s.replace('’', \"'\")\n",
    "    s = s.replace('—', '-')\n",
    "    s = s.replace('–', '-')\n",
    "    s = s.replace('…', '...')\n",
    "    s = s.replace('„', '\"')\n",
    "    return s\n",
    "\n",
    "def is_non_english(s):\n",
    "    return any(ord(el) > 256 and el not in {'‘', '’'} for el in s)\n",
    "\n",
    "class DatasetCleaner:\n",
    "    def __init__(self, max_text_tokens=400, banned=None, banned_phrases=None):\n",
    "        self.max_text_tokens = max_text_tokens\n",
    "        if banned is None:\n",
    "            self.banned = [\"are-you-happy-with-your-choices~3f.json\", \"Warlords~3a-Strategic-Conquest.json\", \n",
    "                        \"Survive-or-Conquer.json\", \"Maintenance-Systems.json\", \"Sixteen-Words.json\", \n",
    "                        \"How-well-do-you-know-your-British~2dEnglish~3f.json\",\n",
    "                        \"Harry-Potter-and-the-Deathly-Hallows-Quiz.json\",\n",
    "                        \"Monster-Trivia.json\", \"Z~2dDAY-Survival-Quiz.json\", \n",
    "                        \"Battlefield-Commander~3a-Ancient-Warfare.json\", \n",
    "                        \"Algebra-Game.json\", \"Tower-of-Doom.json\", \"Practice-Simple-Italian.json\", \n",
    "                        \"ENG4U1-Seminar-Game.json\", \"Eating-Disorders-Midterm.json\",\n",
    "                          \"Strategy-Simulator.json\", \"You~21.json\", \"WWII-Grand-Strategy.json\", \"Attack: 10|100|00|00\"]\n",
    "        else:\n",
    "            self.banned = banned\n",
    "        \n",
    "        if banned_phrases is None:\n",
    "            self.banned_phrases = [\"Synopsis\", \"MENU\", \"HARD\", \"EASY\", \"MEDIUM\", \"Turn to Section\", \"go to section\", \n",
    "              \"turn to page\", \"go to page\", \"\t\t\t\", \"Start over\", \"END THE GAME\", \"Rating:\",\n",
    "             \"Rank:\", \"THE END\", \"The end\", \"The End\", \"Please play again\", \"YOUR HEALTH\", \n",
    "              \"Your score was\", \"Your score is\"] \n",
    "        else:\n",
    "            self.banned_phrases = banned_phrases       \n",
    "    \n",
    "    def process(self, input_dir, output_dir):\n",
    "        files = [el for el in os.listdir(input_dir)]\n",
    "        written = 0\n",
    "        for el in tqdm(files):\n",
    "            if any(ban in el for ban in self.banned):\n",
    "                continue\n",
    "            j = json.load(open(os.path.join(input_dir, el)))\n",
    "            allowed_nodes = dict()      \n",
    "            bad_nodes = 0\n",
    "            bad_actions = 0\n",
    "            total_actions = 0\n",
    "            for key, state in j.items():\n",
    "                curr_actions = [normalize_text(t) for t in state['query_texts']]\n",
    "                text = normalize_text(state['main_text'])\n",
    "                if any(ban in el for ban in self.banned_phrases) or \\\n",
    "                   len(tokenizer.encode(text)) > self.max_text_tokens:\n",
    "                    bad_nodes += 1\n",
    "                    continue\n",
    "                if is_non_english(text):\n",
    "                    bad_nodes += 1\n",
    "                    continue\n",
    "                total_actions += len(curr_actions)\n",
    "                allowed_actions = []\n",
    "                allowed_nums = []\n",
    "                for action, state in zip(curr_actions, state[\"next_nums\"]):\n",
    "                    if any(ban in action for ban in self.banned_phrases):\n",
    "                        bad_actions += 1\n",
    "                    if is_non_english(action):\n",
    "                        continue\n",
    "                    if str(state) not in j:\n",
    "                        continue\n",
    "                    allowed_actions.append(action)\n",
    "                    allowed_nums.append(str(state))\n",
    "                \n",
    "                node = {\n",
    "                    \"query_texts\": allowed_actions,\n",
    "                    \"next_nums\": allowed_nums,\n",
    "                    \"main_text\": text,\n",
    "                }\n",
    "                allowed_nodes[str(key)] = node\n",
    "            \n",
    "            for t in allowed_nodes:\n",
    "                allowed_actions = []\n",
    "                allowed_nums = []\n",
    "                for action, state in zip(allowed_nodes[t]['query_texts'], allowed_nodes[t][\"next_nums\"]):\n",
    "                    if state not in allowed_nodes:\n",
    "                        bad_actions += 1\n",
    "                        continue\n",
    "                    allowed_actions.append(action)\n",
    "                    allowed_nums.append(state)\n",
    "                allowed_nodes[t]['query_texts'] = allowed_actions\n",
    "                allowed_nodes[t]['next_nums'] = allowed_nums\n",
    "                \n",
    "            if bad_nodes / len(j) >= 0.3:\n",
    "                continue\n",
    "            if bad_nodes / len(j) >= 0.2:\n",
    "                print(f\"File: {el} Nodes banned: {bad_nodes}/{len(j)} Actions banned: {bad_actions}/{total_actions}\")\n",
    "            with open(os.path.join(output_dir, el), \"w\") as file:\n",
    "                json.dump(allowed_nodes, fp=file)\n",
    "                written += 1\n",
    "        print(written/len(files), written, len(files))\n",
    "\n",
    "DatasetCleaner().process(\"data\", \"data_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "061be575",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_k = 8\n",
    "val_k = 1\n",
    "test_k = 1\n",
    "total_k = train_k + val_k + test_k\n",
    "train_dir = \"data_train\"\n",
    "val_dir = \"data_val\"\n",
    "test_dir = \"data_test\"\n",
    "files = sorted(os.listdir(\"data_cleaned\"))\n",
    "random.seed(42)\n",
    "for file in files:\n",
    "    c = random.randint(1, total_k)\n",
    "    if c <= train_k:\n",
    "        os.system(f'cp \"{os.path.join(\"data_cleaned\", file)}\" \"{os.path.join(train_dir, file)}\"')\n",
    "    elif c <= train_k + val_k:\n",
    "        os.system(f'cp \"{os.path.join(\"data_cleaned\", file)}\" \"{os.path.join(val_dir, file)}\"')\n",
    "    else:\n",
    "        os.system(f'cp \"{os.path.join(\"data_cleaned\", file)}\" \"{os.path.join(test_dir, file)}\"')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e936802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!mkdir data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40a4fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm data_cleaned/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37af555",
   "metadata": {},
   "source": [
    "left - thr\n",
    "\n",
    "0.75 - 0.35\n",
    "\n",
    "0.72 - 0.3\n",
    "\n",
    "0.701 - 0.25\n",
    "\n",
    "0.6517 - 0.2\n",
    "\n",
    "0.605 - 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c676fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGdCAYAAAAPLEfqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqVUlEQVR4nO3df1RVdb7/8ReIgFYHVORXoWKWv3+FiqeymyNX/DE1Tt6+6lhjjVl50UlpzOyHWnPvpWU3y4q0brdorZtZzZ2cUsMQf1WiJkmKKaNFYekBR4WjXkWFz/ePhj0eRfqI6Dno87HWXouzP2/2ee/P0sNrnb3P5wQZY4wAAABQp2B/NwAAANAYEJoAAAAsEJoAAAAsEJoAAAAsEJoAAAAsEJoAAAAsEJoAAAAsEJoAAAAshPi7gUtFdXW19uzZo6uuukpBQUH+bgcAAFgwxujQoUOKj49XcHDd7yURmhrInj17lJCQ4O82AABAPezevVvXXHNNnTWEpgZy1VVXSfpp0l0ul5+7AQAANrxerxISEpy/43UhNDWQmktyLpeL0AQAQCNjc2sNN4IDAABYIDQBAABYIDQBAABYIDQBAABYIDQBAABYIDQBAABYIDQBAABYIDQBAABYIDQBAABYIDQBAABYIDQBAABYIDQBAABYIDQBAABYIDQBAABYCPF3A7CTMuw27S39W61jcTFRWrHso4vcEQAAlxdCUyOxt/Rv6v7A3FrHtr6afpG7AQDg8sPlOQAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAt+DU0ZGRnq27evrrrqKkVHR2vEiBEqKiryqTl27JjS0tLUqlUrXXnllRo5cqRKS0t9akpKSjR8+HA1b95c0dHRmjZtmk6ePOlTs3r1at1www0KCwtThw4dlJWVdUY/mZmZateuncLDw5WcnKyNGzc2+DkDAIDGya+hac2aNUpLS9P69euVk5OjEydOaPDgwTpy5IhTM3XqVH300Ud6//33tWbNGu3Zs0d33HGHM15VVaXhw4fr+PHjWrdund566y1lZWVp5syZTk1xcbGGDx+ugQMHqqCgQFOmTNF9992n5cuXOzXvvvuu0tPTNWvWLH355Zfq2bOnUlNTVVZWdnEmAwAABLQgY4zxdxM19u3bp+joaK1Zs0a33HKLKioq1Lp1ay1cuFD/8i//IknasWOHOnfurLy8PPXv318ff/yxfvnLX2rPnj2KiYmRJC1YsEDTp0/Xvn37FBoaqunTp2vp0qUqLCx0nmv06NEqLy9Xdna2JCk5OVl9+/bVyy+/LEmqrq5WQkKCJk+erEcfffRne/d6vYqIiFBFRYVcLldDT426JrnV/YG5tY5tfTVd2/LzGvw5AQC41J3L3++AuqepoqJCktSyZUtJUn5+vk6cOKGUlBSnplOnTmrTpo3y8n4KCXl5eerevbsTmCQpNTVVXq9X27Ztc2pOPUZNTc0xjh8/rvz8fJ+a4OBgpaSkODUAAODyFuLvBmpUV1drypQpuummm9StWzdJksfjUWhoqCIjI31qY2Ji5PF4nJpTA1PNeM1YXTVer1dHjx7VwYMHVVVVVWvNjh07au23srJSlZWVzmOv13uOZwwAABqTgHmnKS0tTYWFhVq0aJG/W7GSkZGhiIgIZ0tISPB3SwAA4AIKiNA0adIkLVmyRKtWrdI111zj7I+NjdXx48dVXl7uU19aWqrY2Fin5vRP09U8/rkal8ulZs2aKSoqSk2aNKm1puYYp5sxY4YqKiqcbffu3ed+4gAAoNHwa2gyxmjSpEn64IMPtHLlSiUmJvqMJyUlqWnTpsrNzXX2FRUVqaSkRG63W5Lkdru1detWn0+55eTkyOVyqUuXLk7Nqceoqak5RmhoqJKSknxqqqurlZub69ScLiwsTC6Xy2cDAACXLr/e05SWlqaFCxfqL3/5i6666irnHqSIiAg1a9ZMERERGj9+vNLT09WyZUu5XC5NnjxZbrdb/fv3lyQNHjxYXbp00d133605c+bI4/HoiSeeUFpamsLCwiRJDz74oF5++WU98sgj+t3vfqeVK1fqvffe09KlS51e0tPTNW7cOPXp00f9+vXTCy+8oCNHjujee++9+BMDAAACjl9D0/z58yVJt956q8/+N998U/fcc48k6fnnn1dwcLBGjhypyspKpaam6pVXXnFqmzRpoiVLlmjixIlyu9264oorNG7cOD399NNOTWJiopYuXaqpU6dq3rx5uuaaa/T6668rNTXVqRk1apT27dunmTNnyuPxqFevXsrOzj7j5nAAAHB5Cqh1mhoz1mkCAKDxabTrNAEAAAQqQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAIAFQhMAAICFEH83gPNX8v336prkPut4XEyUViz76CJ2BADApYfQdAmoMlL3B+aedXzrq+kXsRsAAC5NXJ4DAACwQGgCAACwQGgCAACwQGgCAACwQGgCAACwQGgCAACw4NfQtHbtWt12222Kj49XUFCQFi9e7DN+zz33KCgoyGcbMmSIT82BAwc0duxYuVwuRUZGavz48Tp8+LBPzZYtWzRgwACFh4crISFBc+bMOaOX999/X506dVJ4eLi6d++uZcuWNfj5AgCAxsuvoenIkSPq2bOnMjMzz1ozZMgQ7d2719neeecdn/GxY8dq27ZtysnJ0ZIlS7R27Vrdf//9zrjX69XgwYPVtm1b5efn69lnn9Xs2bP12muvOTXr1q3TmDFjNH78eG3evFkjRozQiBEjVFhY2PAnDQAAGiW/Lm45dOhQDR06tM6asLAwxcbG1jq2fft2ZWdn64svvlCfPn0kSS+99JKGDRum//zP/1R8fLzefvttHT9+XG+88YZCQ0PVtWtXFRQUaO7cuU64mjdvnoYMGaJp06ZJkv74xz8qJydHL7/8shYsWNCAZwwAABqrgL+nafXq1YqOjlbHjh01ceJE7d+/3xnLy8tTZGSkE5gkKSUlRcHBwdqwYYNTc8sttyg0NNSpSU1NVVFRkQ4ePOjUpKSk+Dxvamqq8vLyLuSpAQCARiSgv0ZlyJAhuuOOO5SYmKhvvvlGjz32mIYOHaq8vDw1adJEHo9H0dHRPr8TEhKili1byuPxSJI8Ho8SExN9amJiYpyxFi1ayOPxOPtOrak5Rm0qKytVWVnpPPZ6ved1rgAAILAFdGgaPXq083P37t3Vo0cPXXvttVq9erUGDRrkx86kjIwMPfXUU37tAQAAXDwBf3nuVO3bt1dUVJR27dolSYqNjVVZWZlPzcmTJ3XgwAHnPqjY2FiVlpb61NQ8/rmas91LJUkzZsxQRUWFs+3evfv8Tg4AAAS0RhWafvjhB+3fv19xcXGSJLfbrfLycuXn5zs1K1euVHV1tZKTk52atWvX6sSJE05NTk6OOnbsqBYtWjg1ubm5Ps+Vk5Mjt9t91l7CwsLkcrl8NgAAcOnya2g6fPiwCgoKVFBQIEkqLi5WQUGBSkpKdPjwYU2bNk3r16/Xd999p9zcXP3qV79Shw4dlJqaKknq3LmzhgwZogkTJmjjxo36/PPPNWnSJI0ePVrx8fGSpN/85jcKDQ3V+PHjtW3bNr377ruaN2+e0tPTnT4eeughZWdn67nnntOOHTs0e/Zsbdq0SZMmTbrocwIAAAKTX0PTpk2b1Lt3b/Xu3VuSlJ6ert69e2vmzJlq0qSJtmzZottvv13XX3+9xo8fr6SkJH366acKCwtzjvH222+rU6dOGjRokIYNG6abb77ZZw2miIgIffLJJyouLlZSUpIefvhhzZw502ctpxtvvFELFy7Ua6+9pp49e+pPf/qTFi9erG7dul28yQAAAAHNrzeC33rrrTLGnHV8+fLlP3uMli1bauHChXXW9OjRQ59++mmdNXfeeafuvPPOn30+AABweWpU9zQBAAD4C6EJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAQr1CU/v27bV///4z9peXl6t9+/bn3RQAAECgqVdo+u6771RVVXXG/srKSv3444/n3RQAAECgCTmX4g8//ND5efny5YqIiHAeV1VVKTc3V+3atWuw5gAAAALFOYWmESNGSJKCgoI0btw4n7GmTZuqXbt2eu655xqsOQAAgEBxTqGpurpakpSYmKgvvvhCUVFRF6QpAACAQHNOoalGcXFxQ/cBAAAQ0OoVmiQpNzdXubm5Kisrc96BqvHGG2+cd2MAAACBpF6h6amnntLTTz+tPn36KC4uTkFBQQ3dFwAAQECpV2hasGCBsrKydPfddzd0PwAAAAGpXus0HT9+XDfeeGND9wIAABCw6hWa7rvvPi1cuLChewEAAAhY9bo8d+zYMb322mtasWKFevTooaZNm/qMz507t0GaAwAACBT1Ck1btmxRr169JEmFhYU+Y9wUDgAALkX1Ck2rVq1q6D4AAAACWr3uaQIAALjc1OudpoEDB9Z5GW7lypX1bggAACAQ1Ss01dzPVOPEiRMqKChQYWHhGV/kCwAAcCmoV2h6/vnna90/e/ZsHT58+LwaAgAACEQNek/TXXfdxffOAQCAS1KDhqa8vDyFh4c35CEBAAACQr0uz91xxx0+j40x2rt3rzZt2qQnn3yyQRoDAAAIJPUKTRERET6Pg4OD1bFjRz399NMaPHhwgzQGAAAQSOoVmt58882G7gMAACCg1Ss01cjPz9f27dslSV27dlXv3r0bpCkAAIBAU6/QVFZWptGjR2v16tWKjIyUJJWXl2vgwIFatGiRWrdu3ZA9AgAA+F29Pj03efJkHTp0SNu2bdOBAwd04MABFRYWyuv16ve//31D9wgAAOB39XqnKTs7WytWrFDnzp2dfV26dFFmZiY3ggMAgEtSvd5pqq6uVtOmTc/Y37RpU1VXV593UwAAAIGmXqHpF7/4hR566CHt2bPH2ffjjz9q6tSpGjRoUIM1BwAAECjqFZpefvlleb1etWvXTtdee62uvfZaJSYmyuv16qWXXmroHgEAAPyuXvc0JSQk6Msvv9SKFSu0Y8cOSVLnzp2VkpLSoM0BAAAEinN6p2nlypXq0qWLvF6vgoKC9M///M+aPHmyJk+erL59+6pr16769NNPL1SvAAAAfnNOoemFF17QhAkT5HK5zhiLiIjQAw88oLlz5zZYcwAAAIHinELTV199pSFDhpx1fPDgwcrPzz/vpgAAAALNOYWm0tLSWpcaqBESEqJ9+/add1MAAACB5pxC09VXX63CwsKzjm/ZskVxcXHn3RQAAECgOafQNGzYMD355JM6duzYGWNHjx7VrFmz9Mtf/rLBmgMAAAgU57TkwBNPPKE///nPuv766zVp0iR17NhRkrRjxw5lZmaqqqpKjz/++AVpFAAAwJ/OKTTFxMRo3bp1mjhxombMmCFjjCQpKChIqampyszMVExMzAVpFAAAwJ/OeXHLtm3batmyZTp48KB27dolY4yuu+46tWjR4kL0BwAAEBDqtSK4JLVo0UJ9+/ZtyF4AAAACVr2+ew4AAOByQ2gCAACwQGgCAACwQGgCAACw4NfQtHbtWt12222Kj49XUFCQFi9e7DNujNHMmTMVFxenZs2aKSUlRTt37vSpOXDggMaOHSuXy6XIyEiNHz9ehw8f9qnZsmWLBgwYoPDwcCUkJGjOnDln9PL++++rU6dOCg8PV/fu3bVs2bIGP18AANB4+TU0HTlyRD179lRmZmat43PmzNGLL76oBQsWaMOGDbriiiuUmprqsyL52LFjtW3bNuXk5GjJkiVau3at7r//fmfc6/Vq8ODBatu2rfLz8/Xss89q9uzZeu2115yadevWacyYMRo/frw2b96sESNGaMSIEXV+ZQwAALi8BJmaFSr9LCgoSB988IFGjBgh6ad3meLj4/Xwww/rD3/4gySpoqJCMTExysrK0ujRo7V9+3Z16dJFX3zxhfr06SNJys7O1rBhw/TDDz8oPj5e8+fP1+OPPy6Px6PQ0FBJ0qOPPqrFixdrx44dkqRRo0bpyJEjWrJkidNP//791atXLy1YsMCqf6/Xq4iICFVUVMjlcjXUtDi6JrnV/YG5tY59OGOkbs/437P+7tZX07UtP6/BewIAoLE7l7/fAXtPU3FxsTwej1JSUpx9ERERSk5OVl7eTwEgLy9PkZGRTmCSpJSUFAUHB2vDhg1OzS233OIEJklKTU1VUVGRDh486NSc+jw1NTXPU5vKykp5vV6fDQAAXLoCNjR5PB5JOuNrWWJiYpwxj8ej6Ohon/GQkBC1bNnSp6a2Y5z6HGerqRmvTUZGhiIiIpwtISHhXE8RAAA0IgEbmgLdjBkzVFFR4Wy7d+/2d0sAAOACCtjQFBsbK0kqLS312V9aWuqMxcbGqqyszGf85MmTOnDggE9Nbcc49TnOVlMzXpuwsDC5XC6fDQAAXLoCNjQlJiYqNjZWubm5zj6v16sNGzbI7XZLktxut8rLy5Wfn+/UrFy5UtXV1UpOTnZq1q5dqxMnTjg1OTk56tixo/Mlw2632+d5ampqngcAAMCvoenw4cMqKChQQUGBpJ9u/i4oKFBJSYmCgoI0ZcoU/du//Zs+/PBDbd26Vb/97W8VHx/vfMKuc+fOGjJkiCZMmKCNGzfq888/16RJkzR69GjFx8dLkn7zm98oNDRU48eP17Zt2/Tuu+9q3rx5Sk9Pd/p46KGHlJ2dreeee047duzQ7NmztWnTJk2aNOliTwkAAAhQIf588k2bNmngwIHO45ogM27cOGVlZemRRx7RkSNHdP/996u8vFw333yzsrOzFR4e7vzO22+/rUmTJmnQoEEKDg7WyJEj9eKLLzrjERER+uSTT5SWlqakpCRFRUVp5syZPms53XjjjVq4cKGeeOIJPfbYY7ruuuu0ePFidevW7SLMAgAAaAwCZp2mxo51mgAAaHwuiXWaAAAAAgmhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwEKIvxvAhVfy/ffqmuSudSwuJkorln10kTsCAKDxITRdBqqM1P2BubWObX01/SJ3AwBA48TlOQAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAsBHZpmz56toKAgn61Tp07O+LFjx5SWlqZWrVrpyiuv1MiRI1VaWupzjJKSEg0fPlzNmzdXdHS0pk2bppMnT/rUrF69WjfccIPCwsLUoUMHZWVlXYzTAwAAjUhAhyZJ6tq1q/bu3etsn332mTM2depUffTRR3r//fe1Zs0a7dmzR3fccYczXlVVpeHDh+v48eNat26d3nrrLWVlZWnmzJlOTXFxsYYPH66BAweqoKBAU6ZM0X333afly5df1PMEAACBLcTfDfyckJAQxcbGnrG/oqJC//3f/62FCxfqF7/4hSTpzTffVOfOnbV+/Xr1799fn3zyib7++mutWLFCMTEx6tWrl/74xz9q+vTpmj17tkJDQ7VgwQIlJibqueeekyR17txZn332mZ5//nmlpqZe1HP1h5Lvv1fXJPdZx+NiorRi2UcXsSMAAAJTwIemnTt3Kj4+XuHh4XK73crIyFCbNm2Un5+vEydOKCUlxant1KmT2rRpo7y8PPXv3195eXnq3r27YmJinJrU1FRNnDhR27ZtU+/evZWXl+dzjJqaKVOm1NlXZWWlKisrncder7dhTvgiqzJS9wfmnnV866vpF7EbAAACV0BfnktOTlZWVpays7M1f/58FRcXa8CAATp06JA8Ho9CQ0MVGRnp8zsxMTHyeDySJI/H4xOYasZrxuqq8Xq9Onr06Fl7y8jIUEREhLMlJCSc7+kCAIAAFtDvNA0dOtT5uUePHkpOTlbbtm313nvvqVmzZn7sTJoxY4bS0//xLozX6yU4AQBwCQvod5pOFxkZqeuvv167du1SbGysjh8/rvLycp+a0tJS5x6o2NjYMz5NV/P452pcLledwSwsLEwul8tnAwAAl65GFZoOHz6sb775RnFxcUpKSlLTpk2Vm5vrjBcVFamkpERu9083Nrvdbm3dulVlZWVOTU5Ojlwul7p06eLUnHqMmpqaYwAAAEgBHpr+8Ic/aM2aNfruu++0bt06/frXv1aTJk00ZswYRUREaPz48UpPT9eqVauUn5+ve++9V263W/3795ckDR48WF26dNHdd9+tr776SsuXL9cTTzyhtLQ0hYWFSZIefPBBffvtt3rkkUe0Y8cOvfLKK3rvvfc0depUf546AAAIMAF9T9MPP/ygMWPGaP/+/WrdurVuvvlmrV+/Xq1bt5YkPf/88woODtbIkSNVWVmp1NRUvfLKK87vN2nSREuWLNHEiRPldrt1xRVXaNy4cXr66aedmsTERC1dulRTp07VvHnzdM011+j111+/LJYbAAAA9gI6NC1atKjO8fDwcGVmZiozM/OsNW3bttWyZcvqPM6tt96qzZs316tHAABweQjoy3MAAACBgtAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABgIcTfDSCwlXz/vbomuWsdi4uJ0oplH13kjgAA8A9CE+pUZaTuD8ytdWzrq+kXuRsAAPyHy3MAAAAWCE0AAAAWCE0AAAAWCE0AAAAWCE0AAAAWCE0AAAAWCE0AAAAWCE0AAAAWCE0AAAAWCE0AAAAWCE0AAAAW+O451FtdX+Yr8YW+AIBLC6EJ9VbXl/lKfKEvAODSwuU5AAAAC4QmAAAAC4QmAAAAC4QmAAAAC4QmAAAAC4QmAAAAC4QmAAAAC4QmAAAACyxuiQumrhXDWS0cANDYEJpwwdS1YjirhQMAGhsuzwEAAFggNAEAAFggNAEAAFggNAEAAFggNAEAAFggNAEAAFggNAEAAFggNAEAAFhgcUv4RV2rhUusGA4ACDyEJvhFXauFS6wYDgAIPFyeAwAAsMA7TQhIfNkvACDQEJoQkPiyXwBAoOHyHAAAgAVCEwAAgAUuz6HRYbkCAIA/EJrQ6PzccgVLHxvJTeQAgAZHaMIlh5vIAQAXAvc0AQAAWOCdJlxWuB8KAFBfhCZcVrgfCgBQX4Sm02RmZurZZ5+Vx+NRz5499dJLL6lfv37+bgsXSV2hqq5AJUmle/coJi6+1jECFwA0foSmU7z77rtKT0/XggULlJycrBdeeEGpqakqKipSdHS0v9uDn/3cu1TFM0YSuADgEkZoOsXcuXM1YcIE3XvvvZKkBQsWaOnSpXrjjTf06KOP+rk7NGb+Clx1jZ3vOGEOwOWG0PR3x48fV35+vmbMmOHsCw4OVkpKivLy8s6or6ysVGVlpfO4oqJCkuT1ei9If1VVJ3Xi6JFax4ypPuvYz43zu4H/uyerq9Xpt3886+9++9RdZx2va+x8x5c/dZc69ep71t8t83gUHRt7zmOSFNu6lT783/dqHbt95P+TZ9/+ev0uAJyu5u+2Mebniw2MMcb8+OOPRpJZt26dz/5p06aZfv36nVE/a9YsI4mNjY2NjY3tEth27979s1mBd5rqacaMGUpP/8dCidXV1Tpw4IBatWqloKCgBn0ur9erhIQE7d69Wy6Xq0GPfalhruwxV/aYK3vMlT3m6txcqPkyxujQoUOKjz/7rQo1CE1/FxUVpSZNmqi0tNRnf2lpqWJruYwQFhamsLAwn32RkZEXskW5XC7+Y1liruwxV/aYK3vMlT3m6txciPmKiIiwqmNF8L8LDQ1VUlKScnNznX3V1dXKzc2V2332m3ABAMDlgXeaTpGenq5x48apT58+6tevn1544QUdOXLE+TQdAAC4fBGaTjFq1Cjt27dPM2fOlMfjUa9evZSdna2YmBi/9hUWFqZZs2adcTkQZ2Ku7DFX9pgre8yVPebq3ATCfAUZY/MZOwAAgMsb9zQBAABYIDQBAABYIDQBAABYIDQBAABYIDQFuMzMTLVr107h4eFKTk7Wxo0b/d3SBbd27Vrddtttio+PV1BQkBYvXuwzbozRzJkzFRcXp2bNmiklJUU7d+70qTlw4IDGjh0rl8ulyMhIjR8/XocPH/ap2bJliwYMGKDw8HAlJCRozpw5F/rUGlRGRob69u2rq666StHR0RoxYoSKiop8ao4dO6a0tDS1atVKV155pUaOHHnGAq4lJSUaPny4mjdvrujoaE2bNk0nT570qVm9erVuuOEGhYWFqUOHDsrKyrrQp9fg5s+frx49ejgL47ndbn388cfOOHNVu2eeeUZBQUGaMmWKs4+5+ofZs2crKCjIZ+vUqZMzzlz5+vHHH3XXXXepVatWatasmbp3765NmzY54wH/+t4Q39uGC2PRokUmNDTUvPHGG2bbtm1mwoQJJjIy0pSWlvq7tQtq2bJl5vHHHzd//vOfjSTzwQcf+Iw/88wzJiIiwixevNh89dVX5vbbbzeJiYnm6NGjTs2QIUNMz549zfr1682nn35qOnToYMaMGeOMV1RUmJiYGDN27FhTWFho3nnnHdOsWTPz6quvXqzTPG+pqanmzTffNIWFhaagoMAMGzbMtGnTxhw+fNipefDBB01CQoLJzc01mzZtMv379zc33nijM37y5EnTrVs3k5KSYjZv3myWLVtmoqKizIwZM5yab7/91jRv3tykp6ebr7/+2rz00kumSZMmJjs7+6Ke7/n68MMPzdKlS81f//pXU1RUZB577DHTtGlTU1hYaIxhrmqzceNG065dO9OjRw/z0EMPOfuZq3+YNWuW6dq1q9m7d6+z7du3zxlnrv7hwIEDpm3btuaee+4xGzZsMN9++61Zvny52bVrl1MT6K/vhKYA1q9fP5OWluY8rqqqMvHx8SYjI8OPXV1cp4em6upqExsba5599llnX3l5uQkLCzPvvPOOMcaYr7/+2kgyX3zxhVPz8ccfm6CgIPPjjz8aY4x55ZVXTIsWLUxlZaVTM336dNOxY8cLfEYXTllZmZFk1qxZY4z5aV6aNm1q3n//fadm+/btRpLJy8szxvwUUIODg43H43Fq5s+fb1wulzM3jzzyiOnatavPc40aNcqkpqZe6FO64Fq0aGFef/115qoWhw4dMtddd53Jyckx//RP/+SEJubK16xZs0zPnj1rHWOufE2fPt3cfPPNZx1vDK/vXJ4LUMePH1d+fr5SUlKcfcHBwUpJSVFeXp4fO/Ov4uJieTwen3mJiIhQcnKyMy95eXmKjIxUnz59nJqUlBQFBwdrw4YNTs0tt9yi0NBQpyY1NVVFRUU6ePDgRTqbhlVRUSFJatmypSQpPz9fJ06c8JmrTp06qU2bNj5z1b17d58FXFNTU+X1erVt2zan5tRj1NQ05n+HVVVVWrRokY4cOSK3281c1SItLU3Dhw8/43yYqzPt3LlT8fHxat++vcaOHauSkhJJzNXpPvzwQ/Xp00d33nmnoqOj1bt3b/3Xf/2XM94YXt8JTQHqb3/7m6qqqs5YjTwmJkYej8dPXflfzbnXNS8ej0fR0dE+4yEhIWrZsqVPTW3HOPU5GpPq6mpNmTJFN910k7p16ybpp/MIDQ0944ukT5+rn5uHs9V4vV4dPXr0QpzOBbN161ZdeeWVCgsL04MPPqgPPvhAXbp0Ya5Os2jRIn355ZfKyMg4Y4y58pWcnKysrCxlZ2dr/vz5Ki4u1oABA3To0CHm6jTffvut5s+fr+uuu07Lly/XxIkT9fvf/15vvfWWpMbx+s7XqACXgLS0NBUWFuqzzz7zdysBrWPHjiooKFBFRYX+9Kc/ady4cVqzZo2/2woou3fv1kMPPaScnByFh4f7u52AN3ToUOfnHj16KDk5WW3bttV7772nZs2a+bGzwFNdXa0+ffroP/7jPyRJvXv3VmFhoRYsWKBx48b5uTs7vNMUoKKiotSkSZMzPmVRWlqq2NhYP3XlfzXnXte8xMbGqqyszGf85MmTOnDggE9Nbcc49Tkai0mTJmnJkiVatWqVrrnmGmd/bGysjh8/rvLycp/60+fq5+bhbDUul6vR/VEIDQ1Vhw4dlJSUpIyMDPXs2VPz5s1jrk6Rn5+vsrIy3XDDDQoJCVFISIjWrFmjF198USEhIYqJiWGu6hAZGanrr79eu3bt4t/VaeLi4tSlSxeffZ07d3YuZzaG13dCU4AKDQ1VUlKScnNznX3V1dXKzc2V2+32Y2f+lZiYqNjYWJ958Xq92rBhgzMvbrdb5eXlys/Pd2pWrlyp6upqJScnOzVr167ViRMnnJqcnBx17NhRLVq0uEhnc36MMZo0aZI++OADrVy5UomJiT7jSUlJatq0qc9cFRUVqaSkxGeutm7d6vMilJOTI5fL5by4ud1un2PU1FwK/w6rq6tVWVnJXJ1i0KBB2rp1qwoKCpytT58+Gjt2rPMzc3V2hw8f1jfffKO4uDj+XZ3mpptuOmNZlL/+9a9q27atpEby+n7et5Ljglm0aJEJCwszWVlZ5uuvvzb333+/iYyM9PmUxaXo0KFDZvPmzWbz5s1Gkpk7d67ZvHmz+f77740xP30kNTIy0vzlL38xW7ZsMb/61a9q/Uhq7969zYYNG8xnn31mrrvuOp+PpJaXl5uYmBhz9913m8LCQrNo0SLTvHnzRrXkwMSJE01ERIRZvXq1z8ed/+///s+pefDBB02bNm3MypUrzaZNm4zb7TZut9sZr/m48+DBg01BQYHJzs42rVu3rvXjztOmTTPbt283mZmZjfLjzo8++qhZs2aNKS4uNlu2bDGPPvqoCQoKMp988okxhrmqy6mfnjOGuTrVww8/bFavXm2Ki4vN559/blJSUkxUVJQpKyszxjBXp9q4caMJCQkx//7v/2527txp3n77bdO8eXPzP//zP05NoL++E5oC3EsvvWTatGljQkNDTb9+/cz69ev93dIFt2rVKiPpjG3cuHHGmJ8+lvrkk0+amJgYExYWZgYNGmSKiop8jrF//34zZswYc+WVVxqXy2Xuvfdec+jQIZ+ar776ytx8880mLCzMXH311eaZZ565WKfYIGqbI0nmzTffdGqOHj1q/vVf/9W0aNHCNG/e3Pz61782e/fu9TnOd999Z4YOHWqaNWtmoqKizMMPP2xOnDjhU7Nq1SrTq1cvExoaatq3b+/zHI3F7373O9O2bVsTGhpqWrdubQYNGuQEJmOYq7qcHpqYq38YNWqUiYuLM6Ghoebqq682o0aN8ll3iLny9dFHH5lu3bqZsLAw06lTJ/Paa6/5jAf663uQMcac33tVAAAAlz7uaQIAALBAaAIAALBAaAIAALBAaAIAALBAaAIAALBAaAIAALBAaAIAALBAaAIAALBAaAIAALBAaAIAALBAaAIAALBAaAIAALDw/wHe7D2I/ThXSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=np.array(descriptions), binwidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0124e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
